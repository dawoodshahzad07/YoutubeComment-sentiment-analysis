{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\Home\\\\Desktop\\\\comments\\\\sentiment_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgzarqjaaPC7TbFINNx4AaABAg</td>\n",
       "      <td>dQw4w9WgXcQ</td>\n",
       "      <td>1 billion views for never gonna give you up  a...</td>\n",
       "      <td>1371237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgzZfeHlzDX8I39KnBN4AaABAg</td>\n",
       "      <td>dQw4w9WgXcQ</td>\n",
       "      <td>somebody in june 2024</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgzZFBL6zRpXgdquvd54AaABAg</td>\n",
       "      <td>dQw4w9WgXcQ</td>\n",
       "      <td>everytime someone likes this comment i will ri...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgycbTjm2ndO6Xai_0h4AaABAg</td>\n",
       "      <td>dQw4w9WgXcQ</td>\n",
       "      <td>when you rickroll someone you have to rickroll...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugzw1uX9tgi1L0mL2dB4AaABAg</td>\n",
       "      <td>dQw4w9WgXcQ</td>\n",
       "      <td>in a few years this will be an anthem</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CommentId      VideoId  \\\n",
       "0  UgzarqjaaPC7TbFINNx4AaABAg  dQw4w9WgXcQ   \n",
       "1  UgzZfeHlzDX8I39KnBN4AaABAg  dQw4w9WgXcQ   \n",
       "2  UgzZFBL6zRpXgdquvd54AaABAg  dQw4w9WgXcQ   \n",
       "3  UgycbTjm2ndO6Xai_0h4AaABAg  dQw4w9WgXcQ   \n",
       "4  Ugzw1uX9tgi1L0mL2dB4AaABAg  dQw4w9WgXcQ   \n",
       "\n",
       "                                                Text    Likes  \n",
       "0  1 billion views for never gonna give you up  a...  1371237  \n",
       "1                              somebody in june 2024     1018  \n",
       "2  everytime someone likes this comment i will ri...       43  \n",
       "3  when you rickroll someone you have to rickroll...       26  \n",
       "4              in a few years this will be an anthem       14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CommentId  500 non-null    object\n",
      " 1   VideoId    500 non-null    object\n",
      " 2   Text       486 non-null    object\n",
      " 3   Likes      500 non-null    int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CommentId', 'VideoId', 'Text', 'Likes'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['CommentId', 'VideoId','Likes']  \n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 billion views for never gonna give you up  a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>somebody in june 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everytime someone likes this comment i will ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when you rickroll someone you have to rickroll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in a few years this will be an anthem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  1 billion views for never gonna give you up  a...\n",
       "1                              somebody in june 2024\n",
       "2  everytime someone likes this comment i will ri...\n",
       "3  when you rickroll someone you have to rickroll...\n",
       "4              in a few years this will be an anthem"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "        text = re.sub(r'\\@w+|\\#', '', text)  # Remove mentions and hashtags\n",
    "        text = re.sub(r\"[^a-zA-Z#]\", \" \", text)  # Remove punctuation\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = text.split()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "        return \" \".join(tokens)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Create sentiment column\n",
    "df['Sentiment'] = df['cleaned_text'].apply(get_sentiment)\n",
    "\n",
    "# Save the updated dataset with the sentiment column\n",
    "df.to_csv('sentiment_dataset_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\Home\\\\Desktop\\\\comments\\\\sentiment_dataset_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle NaN values\n",
    "df['cleaned_text'].replace(np.nan, '', inplace=True)\n",
    "\n",
    "# Assuming the column name for labels is 'Sentiment'\n",
    "label_column = 'Sentiment'\n",
    "\n",
    "# Create a sample Sentiment column for demonstration (this should be replaced with your actual label data)\n",
    "# For demonstration purposes only, you need to replace it with your actual label column\n",
    "df[label_column] = np.random.choice(['positive', 'negative', 'neutral'], len(df))\n",
    "\n",
    "# One-hot encode 'Sentiment' column\n",
    "df_encoded = pd.get_dummies(df[label_column])\n",
    "\n",
    "# Replace original 'Sentiment' column with one-hot encoded columns\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "df.drop(columns=[label_column], inplace=True)\n",
    "\n",
    "# Rename columns to match the requested encoding (0=positive, 1=negative, 2=neutral)\n",
    "df.rename(columns={'positive': 0, 'negative': 1, 'neutral': 2}, inplace=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df[[0, 1, 2]], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
